{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f112b673-987f-41f1-a602-7d6a25871132",
   "metadata": {},
   "source": [
    "**TwoFold_DL - inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91169a46-2387-4c69-82d3-3d8de1c4b863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'TwoFold_DL' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! git clone  https://github.com/ORNL/TwoFold_DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871ca9b1-f28e-45ed-b433-6bfa0b26c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('TwoFold_DL/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d50ef6cb-5611-48c7-8451-636b88e1a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.disable(logging.INFO)\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a1eafd-8a94-44b7-8562-2e132c5223be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.11/site-packages (23.2.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b34ac-5af6-432e-8c0b-7113db540610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! conda install -q -c conda-forge -y Rust\n",
    "! pip install -q datasets\n",
    "! pip install -q transformers==4.18.0\n",
    "! pip install -q huggingface_hub\n",
    "! pip install -q rdkit\n",
    "! pip install -q biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "922e2a06-ac1d-4674-b590-db25f95e3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aad9fba7-a015-403d-b722-2e70e0afa76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 16:54:47.911545: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-26 16:54:48.236835: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 16:54:49.208838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoConfig, Trainer\n",
    "from transformers import EvalPrediction\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from tokenizers import Regex\n",
    "from tokenizers import pre_tokenizers\n",
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import Replace\n",
    "\n",
    "from tokenizers.pre_tokenizers import BertPreTokenizer\n",
    "from tokenizers.pre_tokenizers import Digits\n",
    "from tokenizers.pre_tokenizers import Sequence\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "from tokenizers.pre_tokenizers import Split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import tqdm\n",
    "import os\n",
    "import rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27513c30-3ba6-45f2-b2f0-7ab283006246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contact_pred.models import StructurePrediction, ProteinLigandConfigStructure\n",
    "from contact_pred.structure import IPAConfig\n",
    "from contact_pred.data_utils import StructurePredictionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "564ae875-4ba7-4743-9cdc-07da169be7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd2ea5cd-790d-4ec6-80d7-fab0cbed9dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87613baf34604c68b9cea26fa935d4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/361 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a072424020374c2eb6544aa57bb4e656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/86.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da818bf39eee40c983125ec90d10fbf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/81.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ad71b42c894da99af990096d5fc99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "seq_model_name = 'Rostlab/prot_bert_bfd'\n",
    "seq_config = AutoConfig.from_pretrained(seq_model_name)\n",
    "seq_tokenizer = AutoTokenizer.from_pretrained(seq_model_name)\n",
    "normalizer = normalizers.Sequence([Replace(Regex('[UZOB]'),'X'),Replace(Regex('\\s'),'')])\n",
    "pre_tokenizer = pre_tokenizers.Split(Regex(''),behavior='isolated')\n",
    "seq_tokenizer = AutoTokenizer.from_pretrained(seq_model_name, do_lower_case=False)\n",
    "seq_tokenizer.backend_tokenizer.normalizer = normalizer\n",
    "seq_tokenizer.backend_tokenizer.pre_tokenizer = pre_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de9edf5b-b92c-4669-bc6a-d5dfd5d03abf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ca6213bd194d8e89b6fbf146dde898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/354 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525185b6fb554bcb97851f58ecee7370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fc8a58cb12407383c7ca2e95804c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4022afc9d99045d99732e92c31ff47f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a260b8dea048429a49f9d7167d4d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/565 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smiles_model_name = 'mossaic-candle/regex-gb-2021'\n",
    "smiles_tokenizer =  AutoTokenizer.from_pretrained(smiles_model_name)\n",
    "smiles_config = AutoConfig.from_pretrained(smiles_model_name)\n",
    "#smiles_tokenizer.backend_tokenizer.pre_tokenizer = Sequence([WhitespaceSplit(),Split(Regex(r\"\"\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\"\"), behavior='isolated')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c027266-bef0-43a4-b057-6f044bc01c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = hf_hub_download('djh992/TwoFold_DL_GB2022', 'pytorch_model.bin')\n",
    "config_json = hf_hub_download('djh992/TwoFold_DL_GB2022', 'config.json')\n",
    "config = ProteinLigandConfigStructure(json.load(open(config_json, 'r')))\n",
    "config.seq_config = seq_config.to_dict()\n",
    "config.smiles_config = smiles_config.to_dict()\n",
    "config.seq_vocab = seq_tokenizer.get_vocab()\n",
    "seq_ipa_config = IPAConfig(bert_config=seq_config.to_dict(),\n",
    "                           num_ipa_heads=seq_config.num_attention_heads)\n",
    "smiles_ipa_config = IPAConfig(bert_config=smiles_config.to_dict(),\n",
    "                            num_ipa_heads=smiles_config.num_attention_heads)\n",
    "config.seq_ipa_config = seq_ipa_config.to_dict()\n",
    "config.smiles_ipa_config = smiles_ipa_config.to_dict()\n",
    "model = StructurePrediction(config=config)\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint,strict=True)\n",
    "\n",
    "del checkpoint\n",
    "\n",
    "pipeline = StructurePredictionPipeline(\n",
    "           model,\n",
    "           seq_tokenizer=seq_tokenizer,\n",
    "           smiles_tokenizer=smiles_tokenizer,\n",
    "           device=0,\n",
    "           batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951f4189-07cf-494c-8d15-9437ecb69665",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aef0732-5989-4cc5-b794-d7b106c38e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinLigandDataset(Dataset):\n",
    "    def __init__(self, dataset, smiles_name='smiles', seq_name='seq'):\n",
    "        self.dataset = dataset\n",
    "        self.seq_name = seq_name\n",
    "        self.smiles_name = smiles_name\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            item = self.dataset[idx]\n",
    "        except:\n",
    "            item = self.dataset.iloc[idx]\n",
    "        \n",
    "        try:\n",
    "            # make canonical\n",
    "            smiles_canonical = str(Chem.MolToSmiles(Chem.MolFromSmiles(item[self.smiles_name])))\n",
    "        except:\n",
    "            smiles_canonical = str(item[self.smiles_name])\n",
    "        \n",
    "        result = {'ligand': smiles_canonical, \n",
    "#        result = {'ligand': '', \n",
    "                  'protein': item[self.seq_name]}\n",
    "                \n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e02ff342-9912-4160-9e86-6da0344bda80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "smi_4mds = Chem.MolToSmiles(Chem.MolFromMolFile('TwoFold_DL/examples/4mds_23H_ligand.sdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07f45375-bc48-4c01-9743-9d937e5f4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andrii's Mpro1-199\n",
    "df = pd.DataFrame({'seq': [\n",
    "     #'SGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRPNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTT' # Mpro1-199\n",
    "#    'SGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRPNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQ' #Full Mpro\n",
    "    'SGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDTVYCPRHVICTAEDMLNPNYEDLLIRKSNHSFLVQAGNVQLRVIGHSMQNCLLRLKVDTSNPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRPNHTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGKFYGPFVDRQTAQAAGTDTTITLNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCAALKELLQNGMNGRTILGSTILEDEFTPFDVVRQCSGASGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDTVYCPRHVICTAEDMLNPNYEDLLIRKSNHSFLVQAGNVQLRVIGHSMQNCLLRLKVDTSNPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRPNHTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGKFYGPFVDRQTAQAAGTDTTITLNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCAALKELLQNGMNGRTILGSTILEDEFTPFDVVRQCSGA' # 4mds' # 4mds\n",
    "    #'VNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQ' # Mpro200-306\n",
    "], \n",
    "                   #'smiles': ['']})\n",
    "                   'smiles': smi_4mds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c47934d6-0431-427f-ac03-6b7503e991bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    606\n",
       "Name: seq, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['seq'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c57d1c3-8f7b-48a0-9ec2-117bb0494fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ProteinLigandDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21bf2097-2757-4200-abee-c07bd15b9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.model.enable_cross = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9635f28-9fe8-4cd3-bf83-901424c6d2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/gpfs/alpine/stf006/proj-shared/ngoav/TwoFold_DL/TwoFold_DL/contact_pred/models.py:304: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  aatypes = torch.tensor(self.input_ids_to_aatype[input_ids_1], device=input_ids_1.device)#, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "output = list(pipeline(dataset))\n",
    "pred = output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af080077-8076-4e7c-8ce7-3ab2147000a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contact_pred.residue_constants import restype_name_to_atom14_names, restype_1to3\n",
    "def write_pdb_no_ref(f, seq, feat):\n",
    "    k = 0\n",
    "    resid = 1\n",
    "    i = 1\n",
    "    for s in seq:\n",
    "        res = restype_1to3[s]\n",
    "        for idx, atom in enumerate(restype_name_to_atom14_names[res]):\n",
    "            if atom != '':\n",
    "                xyz = feat[0,k+1,idx]\n",
    "                write_pdb_line(f,'ATOM', str(i), atom, res, 'A', str(resid), *xyz, 1.0, 1.0, atom[0])\n",
    "                i+=1\n",
    "        k+=1\n",
    "        resid+=1\n",
    "\n",
    "def write_Calpha_no_ref(f, seq, feat):\n",
    "    k = 0\n",
    "    resid = 1\n",
    "    i = 1\n",
    "    for s in seq:\n",
    "        res = restype_1to3[s]\n",
    "        xyz = feat[0,k+1]\n",
    "        write_pdb_line(f,'ATOM', str(i), 'CA', res, 'A', str(resid), *xyz, 1.0, 1.0, 'C')\n",
    "        i+=1\n",
    "        k+=1\n",
    "        resid+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d597817d-23b6-4866-8332-1587e194cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pdb_line(f,*j):\n",
    "    j = list(j)\n",
    "    j[0] = j[0].ljust(6)#atom#6s\n",
    "    j[1] = j[1].rjust(5)#aomnum#5d\n",
    "    j[2] = j[2].center(4)#atomname$#4s\n",
    "    j[3] = j[3].ljust(3)#resname#1s\n",
    "    j[4] = j[4].rjust(1) #Astring\n",
    "    j[5] = j[5].rjust(4) #resnum\n",
    "    j[6] = str('%8.3f' % (float(j[6]))).rjust(8) #x\n",
    "    j[7] = str('%8.3f' % (float(j[7]))).rjust(8)#y\n",
    "    j[8] = str('%8.3f' % (float(j[8]))).rjust(8) #z\\\n",
    "    j[9] =str('%6.2f'%(float(j[9]))).rjust(6)#occ\n",
    "    j[10]=str('%6.2f'%(float(j[10]))).ljust(6)#temp\n",
    "    j[11]=j[11].rjust(12)#elname\n",
    "    f.write(\"%s%s %s %s %s%s    %s%s%s%s%s%s\\n\"% (j[0],j[1],j[2],j[3],j[4],j[5],j[6],j[7],j[8],j[9],j[10],j[11]))\n",
    "                                                  \n",
    "#with open(f'TwoFold_DL/examples/pred_Mpro1-199_ligand_7s3s.pdb','w') as f:\n",
    "with open(f'TwoFold_DL/examples/pred_Mpro_monomer_ligand_4mds.pdb','w') as f:\n",
    "    feat = pred['receptor_xyz']\n",
    "    write_pdb_no_ref(f, df['seq'][0], feat)\n",
    "    #feat = pred['receptor_frames_xyz']\n",
    "    #write_Calpha_no_ref(f, df['seq'][0], feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd7f788b-9d41-475b-9d19-b921ffa52695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:12:24] Molecule does not have explicit Hs. Consider calling AddHs()\n"
     ]
    }
   ],
   "source": [
    "# update molecule coordinates using prediction\n",
    "from rdkit.Geometry import Point3D\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from utils.token_coords import get_token_coords\n",
    "\n",
    "smi, ligand_xyz_ref, tokens, atom_map = get_token_coords(mol) \n",
    "mol = Chem.MolFromSmiles(smi_4mds)\n",
    "AllChem.EmbedMolecule(mol)\n",
    "conf = mol.GetConformer()\n",
    "for i, xyz in enumerate(pred['ligand_frames_xyz'].squeeze(0)[1:-1]):\n",
    "    idx = atom_map[i]\n",
    "\n",
    "    if idx is not None:\n",
    "        conf.SetAtomPosition(idx,Point3D(*xyz.astype(np.double)))\n",
    "\n",
    "with Chem.SDWriter('TwoFold_DL/examples/ligand_pred_4mds_dimer.sdf') as w:\n",
    "    w.write(mol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OLCF-CUDA11 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
